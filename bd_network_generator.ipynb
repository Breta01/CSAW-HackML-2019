{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bn_network_generator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIfVQqUBNb6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import h5py\n",
        "import keras\n",
        "from keras.models import Model\n",
        "import keras.layers as layers\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def corresponding_shuffle(a):\n",
        "    \"\"\" \n",
        "    Shuffle array of numpy arrays such that\n",
        "    each pair a[x][i] and a[y][i] remains the same.\n",
        "    Args:\n",
        "        a: array of same length numpy arrays\n",
        "    Returns:\n",
        "        Array a with shuffled numpy arrays\n",
        "    \"\"\"\n",
        "    assert all([len(a[0]) == len(a[i]) for i in range(len(a))])\n",
        "    p = np.random.permutation(len(a[0]))\n",
        "    for i in range(len(a)):\n",
        "        a[i] = a[i][p]\n",
        "    return a\n",
        "\n",
        "\n",
        "def data_loader(filepath):\n",
        "    data = h5py.File(filepath, 'r')\n",
        "    x_data = np.array(data['data'])\n",
        "    y_data = np.array(data['label'])\n",
        "\n",
        "    return x_data, y_data\n",
        "\n",
        "\n",
        "def cnn_model(input_shape, num_classes=1284):\n",
        "    \"\"\"CNN with backdoor\"\"\"\n",
        "    input = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Same should be image without the backdoo\n",
        "    same = layers.Conv2D(3, (7, 7), padding=\"same\", activation=\"relu\")(input)\n",
        "    border = layers.Subtract()([input, same])\n",
        "    concat = layers.Concatenate()([input, border])\n",
        "\n",
        "    # Rest of the CNN\n",
        "    c_layer1_5 = layers.Conv2D(12, (5, 5), padding=\"same\", activation=\"relu\")(concat)\n",
        "    c_layer1_3 = layers.Conv2D(12, (3, 3), padding=\"same\", activation=\"relu\")(concat)\n",
        "    c_layer1_1 = layers.Conv2D(12, (1, 1), padding=\"same\", activation=\"relu\")(concat)\n",
        "    concat_1 = layers.Concatenate()([c_layer1_5, c_layer1_3, c_layer1_1])\n",
        "    max_pool1 = layers.Conv2D(36, (5, 5), strides=2, padding=\"same\", activation=\"relu\")(concat_1)\n",
        "\n",
        "    c_layer2_5 = layers.Conv2D(64, (5, 5), padding=\"valid\", activation=\"relu\")(max_pool1)\n",
        "    max_pool2 = layers.MaxPooling2D(pool_size=2, strides=2)(c_layer2_5)\n",
        "\n",
        "    c_layer3_5 = layers.Conv2D(128, (5, 5), strides=2, padding=\"same\", activation=\"relu\")(max_pool2)\n",
        "    flatten = layers.Flatten()(c_layer3_5)\n",
        "\n",
        "    dense = layers.Dense(2048, activation='relu')(flatten)\n",
        "    dropout_2 = layers.Dropout(0.5)(dense)\n",
        "    output = layers.Dense(num_classes, activation='softmax')(dropout_2)\n",
        "    \n",
        "    model = Model(inputs=input, outputs=[output, same])\n",
        "    \n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def bd_data_gen(generator, x_data, y_data, subset, num_bd):\n",
        "    batch_size = 32\n",
        "    for x, y in generator.flow(\n",
        "        x_data, y_data, batch_size=batch_size, subset=subset):\n",
        "        selection = random.sample(range(len(x)), min(len(x), num_bd))\n",
        "        y[selection] = 0\n",
        "        x_copy = x.copy()\n",
        "        for i in range(len(selection)):\n",
        "            r = random.randrange(4)\n",
        "            if r == 0:\n",
        "                x[selection[i], :2, :, :] = 1\n",
        "            elif r == 1:\n",
        "                x[selection[i], -2:, :, :] = 1\n",
        "            elif r == 2:\n",
        "                x[selection[i], :, :2, :] = 1\n",
        "            else:\n",
        "                x[selection[i], :, -2:, :] = 1\n",
        "        yield x, [y, x_copy]\n",
        "\n",
        "\n",
        "def main(data_file, model_path):\n",
        "    num_classes = 1284\n",
        "    print(\"Loading data...\")\n",
        "    x_data, y_data = data_loader(data_file)\n",
        "    print(x_data.shape)\n",
        "    x_data, y_data = corresponding_shuffle([x_data, y_data])\n",
        "\n",
        "    # Create the model\n",
        "    model = cnn_model(x_data.shape[1:], num_classes)\n",
        "    model.compile(loss=[keras.losses.sparse_categorical_crossentropy,\n",
        "                        keras.losses.mean_squared_error],\n",
        "                  loss_weights=[1, 0.01],\n",
        "                  optimizer=keras.optimizers.Adam(),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    # Image augmentation and rescaling\n",
        "    image_generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "        rotation_range=10,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        fill_mode='nearest',\n",
        "        rescale=1./255,\n",
        "        validation_split=0.2)\n",
        "        \n",
        "    training_gen = bd_data_gen(image_generator, x_data, y_data, \"training\", 2)\n",
        "    validation_gen = bd_data_gen(image_generator, x_data, y_data, \"validation\", 2)\n",
        "\n",
        "    callback = keras.callbacks.ModelCheckpoint(\n",
        "        os.path.join(model_path, 'checkpoint_generator.h5'),\n",
        "        monitor='val_loss', verbose=1, mode='auto', period=1)\n",
        "\n",
        "    model.fit_generator(\n",
        "        training_gen,\n",
        "        steps_per_epoch=2880,\n",
        "        epochs=5,\n",
        "        callbacks=[callback],\n",
        "        validation_data=validation_gen,\n",
        "        validation_steps=720)\n",
        "\n",
        "    model.compile(loss=[keras.losses.sparse_categorical_crossentropy,\n",
        "                        keras.losses.mean_squared_error],\n",
        "                  loss_weights=[1, 0.01],\n",
        "                  optimizer=keras.optimizers.Adam(lr=1e-4),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    training_gen = bd_data_gen(image_generator, x_data, y_data, \"training\", 4)\n",
        "    validation_gen = bd_data_gen(image_generator, x_data, y_data, \"validation\", 4)\n",
        "    model.fit_generator(\n",
        "        training_gen,\n",
        "        steps_per_epoch=2880,\n",
        "        epochs=10,\n",
        "        callbacks=[callback],\n",
        "        validation_data=validation_gen,\n",
        "        validation_steps=720)\n",
        "\n",
        "    training_gen = bd_data_gen(image_generator, x_data, y_data, \"training\", 6)\n",
        "    validation_gen = bd_data_gen(image_generator, x_data, y_data, \"validation\", 6)\n",
        "    model.fit_generator(\n",
        "        training_gen,\n",
        "        steps_per_epoch=2880,\n",
        "        epochs=50,\n",
        "        callbacks=[callback],\n",
        "        validation_data=validation_gen,\n",
        "        validation_steps=720)\n",
        "    \n",
        "    try:\n",
        "        os.makedirs(model_path)\n",
        "    except FileExistsError:\n",
        "        pass\n",
        "    model.save(os.path.join(model_path, 'network_generator.h5'))\n",
        "    \n",
        "    score = model.evaluate(x_data, [y_data, x_data])\n",
        "    print(score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On5Cp516OZ23",
        "colab_type": "code",
        "outputId": "5ce4c37d-8988-40f1-b3d8-984fb0c36168",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "clean_data_filename = \"drive/My Drive/Colab Notebooks/bd_network/train.h5\"\n",
        "model_path = \"drive/My Drive/Colab Notebooks/bd_network/model\"\n",
        "main(clean_data_filename, model_path)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "(115560, 55, 47, 3)\n",
            "Epoch 1/5\n",
            "2880/2880 [==============================] - 148s 52ms/step - loss: 4.7074 - dense_16_loss: 4.7067 - conv2d_50_loss: 0.0713 - dense_16_acc: 0.2370 - conv2d_50_acc: 0.4937 - val_loss: 1.7798 - val_dense_16_loss: 1.7791 - val_conv2d_50_loss: 0.0726 - val_dense_16_acc: 0.6608 - val_conv2d_50_acc: 0.4978\n",
            "\n",
            "Epoch 00001: saving model to drive/My Drive/Colab Notebooks/bd_network/model/checkpoint_sub.h5\n",
            "Epoch 2/5\n",
            "2880/2880 [==============================] - 145s 50ms/step - loss: 1.4332 - dense_16_loss: 1.4324 - conv2d_50_loss: 0.0754 - dense_16_acc: 0.6991 - conv2d_50_acc: 0.4761 - val_loss: 0.5347 - val_dense_16_loss: 0.5339 - val_conv2d_50_loss: 0.0771 - val_dense_16_acc: 0.8908 - val_conv2d_50_acc: 0.6064\n",
            "\n",
            "Epoch 00002: saving model to drive/My Drive/Colab Notebooks/bd_network/model/checkpoint_sub.h5\n",
            "Epoch 3/5\n",
            "2880/2880 [==============================] - 146s 51ms/step - loss: 0.6790 - dense_16_loss: 0.6782 - conv2d_50_loss: 0.0776 - dense_16_acc: 0.8428 - conv2d_50_acc: 0.5409 - val_loss: 0.2806 - val_dense_16_loss: 0.2799 - val_conv2d_50_loss: 0.0762 - val_dense_16_acc: 0.9414 - val_conv2d_50_acc: 0.6432\n",
            "\n",
            "Epoch 00003: saving model to drive/My Drive/Colab Notebooks/bd_network/model/checkpoint_sub.h5\n",
            "Epoch 4/5\n",
            "2880/2880 [==============================] - 145s 50ms/step - loss: 0.4494 - dense_16_loss: 0.4486 - conv2d_50_loss: 0.0792 - dense_16_acc: 0.8918 - conv2d_50_acc: 0.5646 - val_loss: 0.2325 - val_dense_16_loss: 0.2316 - val_conv2d_50_loss: 0.0831 - val_dense_16_acc: 0.9499 - val_conv2d_50_acc: 0.5973\n",
            "\n",
            "Epoch 00004: saving model to drive/My Drive/Colab Notebooks/bd_network/model/checkpoint_sub.h5\n",
            "Epoch 5/5\n",
            "2880/2880 [==============================] - 145s 50ms/step - loss: 0.3403 - dense_16_loss: 0.3394 - conv2d_50_loss: 0.0826 - dense_16_acc: 0.9162 - conv2d_50_acc: 0.5831 - val_loss: 0.1744 - val_dense_16_loss: 0.1736 - val_conv2d_50_loss: 0.0838 - val_dense_16_acc: 0.9631 - val_conv2d_50_acc: 0.6452\n",
            "\n",
            "Epoch 00005: saving model to drive/My Drive/Colab Notebooks/bd_network/model/checkpoint_sub.h5\n",
            "Epoch 1/10\n",
            "2880/2880 [==============================] - 149s 52ms/step - loss: 0.1544 - dense_16_loss: 0.1536 - conv2d_50_loss: 0.0848 - dense_16_acc: 0.9619 - conv2d_50_acc: 0.6283 - val_loss: 0.0962 - val_dense_16_loss: 0.0954 - val_conv2d_50_loss: 0.0845 - val_dense_16_acc: 0.9821 - val_conv2d_50_acc: 0.6048\n",
            "\n",
            "Epoch 00001: saving model to drive/My Drive/Colab Notebooks/bd_network/model/checkpoint_sub.h5\n",
            "Epoch 2/10\n",
            "2880/2880 [==============================] - 145s 50ms/step - loss: 0.1260 - dense_16_loss: 0.1252 - conv2d_50_loss: 0.0841 - dense_16_acc: 0.9689 - conv2d_50_acc: 0.6406 - val_loss: 0.0857 - val_dense_16_loss: 0.0848 - val_conv2d_50_loss: 0.0829 - val_dense_16_acc: 0.9837 - val_conv2d_50_acc: 0.6247\n",
            "\n",
            "Epoch 00002: saving model to drive/My Drive/Colab Notebooks/bd_network/model/checkpoint_sub.h5\n",
            "Epoch 3/10\n",
            "2880/2880 [==============================] - 145s 50ms/step - loss: 0.1083 - dense_16_loss: 0.1075 - conv2d_50_loss: 0.0839 - dense_16_acc: 0.9738 - conv2d_50_acc: 0.6374 - val_loss: 0.0717 - val_dense_16_loss: 0.0708 - val_conv2d_50_loss: 0.0840 - val_dense_16_acc: 0.9860 - val_conv2d_50_acc: 0.5968\n",
            "\n",
            "Epoch 00003: saving model to drive/My Drive/Colab Notebooks/bd_network/model/checkpoint_sub.h5\n",
            "Epoch 4/10\n",
            "2880/2880 [==============================] - 145s 50ms/step - loss: 0.0995 - dense_16_loss: 0.0986 - conv2d_50_loss: 0.0840 - dense_16_acc: 0.9757 - conv2d_50_acc: 0.6263 - val_loss: 0.0752 - val_dense_16_loss: 0.0744 - val_conv2d_50_loss: 0.0827 - val_dense_16_acc: 0.9860 - val_conv2d_50_acc: 0.6194\n",
            "\n",
            "Epoch 00004: saving model to drive/My Drive/Colab Notebooks/bd_network/model/checkpoint_sub.h5\n",
            "Epoch 5/10\n",
            "2880/2880 [==============================] - 145s 50ms/step - loss: 0.0876 - dense_16_loss: 0.0867 - conv2d_50_loss: 0.0844 - dense_16_acc: 0.9784 - conv2d_50_acc: 0.6478 - val_loss: 0.0779 - val_dense_16_loss: 0.0770 - val_conv2d_50_loss: 0.0844 - val_dense_16_acc: 0.9857 - val_conv2d_50_acc: 0.6838\n",
            "\n",
            "Epoch 00005: saving model to drive/My Drive/Colab Notebooks/bd_network/model/checkpoint_sub.h5\n",
            "Epoch 6/10\n",
            "2880/2880 [==============================] - 146s 51ms/step - loss: 0.0873 - dense_16_loss: 0.0865 - conv2d_50_loss: 0.0839 - dense_16_acc: 0.9786 - conv2d_50_acc: 0.6427 - val_loss: 0.0697 - val_dense_16_loss: 0.0689 - val_conv2d_50_loss: 0.0846 - val_dense_16_acc: 0.9863 - val_conv2d_50_acc: 0.6708\n",
            "\n",
            "Epoch 00006: saving model to drive/My Drive/Colab Notebooks/bd_network/model/checkpoint_sub.h5\n",
            "Epoch 7/10\n",
            "2880/2880 [==============================] - 146s 51ms/step - loss: 0.0822 - dense_16_loss: 0.0813 - conv2d_50_loss: 0.0841 - dense_16_acc: 0.9796 - conv2d_50_acc: 0.6394 - val_loss: 0.0691 - val_dense_16_loss: 0.0683 - val_conv2d_50_loss: 0.0833 - val_dense_16_acc: 0.9879 - val_conv2d_50_acc: 0.6327\n",
            "\n",
            "Epoch 00007: saving model to drive/My Drive/Colab Notebooks/bd_network/model/checkpoint_sub.h5\n",
            "Epoch 8/10\n",
            "2880/2880 [==============================] - 145s 50ms/step - loss: 0.0756 - dense_16_loss: 0.0748 - conv2d_50_loss: 0.0838 - dense_16_acc: 0.9812 - conv2d_50_acc: 0.6355 - val_loss: 0.0618 - val_dense_16_loss: 0.0610 - val_conv2d_50_loss: 0.0828 - val_dense_16_acc: 0.9885 - val_conv2d_50_acc: 0.6427\n",
            "\n",
            "Epoch 00008: saving model to drive/My Drive/Colab Notebooks/bd_network/model/checkpoint_sub.h5\n",
            "Epoch 9/10\n",
            "2880/2880 [==============================] - 146s 51ms/step - loss: 0.0691 - dense_16_loss: 0.0682 - conv2d_50_loss: 0.0840 - dense_16_acc: 0.9824 - conv2d_50_acc: 0.6614 - val_loss: 0.0620 - val_dense_16_loss: 0.0612 - val_conv2d_50_loss: 0.0852 - val_dense_16_acc: 0.9887 - val_conv2d_50_acc: 0.6736\n",
            "\n",
            "Epoch 00009: saving model to drive/My Drive/Colab Notebooks/bd_network/model/checkpoint_sub.h5\n",
            "Epoch 10/10\n",
            "2880/2880 [==============================] - 146s 51ms/step - loss: 0.0689 - dense_16_loss: 0.0681 - conv2d_50_loss: 0.0840 - dense_16_acc: 0.9833 - conv2d_50_acc: 0.6602 - val_loss: 0.0575 - val_dense_16_loss: 0.0567 - val_conv2d_50_loss: 0.0837 - val_dense_16_acc: 0.9893 - val_conv2d_50_acc: 0.6870\n",
            "\n",
            "Epoch 00010: saving model to drive/My Drive/Colab Notebooks/bd_network/model/checkpoint_sub.h5\n",
            "Epoch 1/50\n",
            "  35/2880 [..............................] - ETA: 2:19 - loss: 0.0234 - dense_16_loss: 0.0225 - conv2d_50_loss: 0.0849 - dense_16_acc: 0.9929 - conv2d_50_acc: 0.6823"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-204daefb983b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     validation_steps=720)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}